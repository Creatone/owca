# Copyright (c) 2018 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import os

include('../common.aurora')

#----------------------------------------------------------------------------------------------------
###
# Params which can be modified by exporting environment variables.
###

# Batch size and epochs.
tensorflow_train_batch_size = os.environ.get('tensorflow_train_batch_size', '100')
tensorflow_train_epochs = os.environ.get('tensorflow_train_epochs', '100')

# Docker image tag.
tensorflow_train_image_tag = os.environ.get('tensorflow_train_image_tag')  # Workaround for "force pull images" defect in Aurora.

slo = os.environ.get('tf_train_slo')
#----------------------------------------------------------------------------------------------------


# Add label for identification workload in prometheus.
wrapper_labels["name"] = 'tensorflow_train--%s' % workload_uniq_id
wrapper_labels["load_generator"] = ""
wrapper_labels["application"] = "tensorflow_train"

# resources parameters
cpu = 1
ram = 2 * GB
disk = 2 * GB

# JOB definitions
jobs = [
    Service(
        name='tensorflow_train--%s' % workload_uniq_id,
        cluster=cluster,
        environment='staging' + env_uniq_id,
        role=role,
        enable_hooks=True,
        constraints=dict(own_ip=application_host_ip),
        container=Mesos(image=DockerImage(
            name=docker_registry + '/serenity/tensorflow-train', tag=tensorflow_train_image_tag,
        )),
        task=SequentialTask(
            name='tensorflow_train--%s' % workload_uniq_id,
            resources=Resources(cpu=cpu, ram=ram, disk=disk),
            processes=[
                Process(
                    name='tensorflow_train_run',
                    cmdline="/wrapper.pex --command 'training --dataset_path '/' --batch_size {batch_size} "
                            "--epochs {epochs}' "
                            "--stderr 0 --kafka_brokers '{kafka_brokers}' --kafka_topic {kafka_topic} "
                            "--log_level {log_level} "
                            "--metric_name_prefix 'tensorflow_train_' "
                            "--slo {slo} --sli_metric_name tensorflow_train_images_processed --inverse_sli_metric_value "
                            "--peak_load 1 --load_metric_name const "
                            "--labels \"{labels}\"".format(batch_size=tensorflow_train_batch_size,
                                                           epochs=tensorflow_train_epochs,
                                                           kafka_brokers=wrapper_kafka_brokers,
                                                           log_level=wrapper_log_level,
                                                           kafka_topic='owca_apms_tensorflow_train',
                                                           labels=str(wrapper_labels), slo=slo
                                                           )
                )
            ],
        )
    )
]

hooks = [AddMetadata(wrapper_labels)]
