import os

include('../common.aurora')

#----------------------------------------------------------------------------------------------------
###
# Params which can be modified by exporting environment variables.
###

# Batch size and epochs.
tensorflow_train_batch_size = os.environ.get('tensorflow_train_batch_size', '100')
tensorflow_train_epochs = os.environ.get('tensorflow_train_epochs', '100')

# Docker image tag.
tensorflow_train_image_tag = os.environ.get('tensorflow_train_image_tag')  # Workaround for "force pull images" defect in Aurora.

slo = os.environ.get('tf_train_slo')
#----------------------------------------------------------------------------------------------------


# Add label for identification workload in prometheus.
wrapper_labels["name"] = 'tensorflow_train--%s' % workload_uniq_id
wrapper_labels["load_generator"] = ""
wrapper_labels["application"] = "tensorflow_train"

# resources parameters
cpu = 1
ram = 2 * GB
disk = 2 * GB

# JOB definitions
jobs = [
    Service(
        name='tensorflow_train--%s' % workload_uniq_id,
        cluster=cluster,
        environment='staging' + env_uniq_id,
        role=role,
        enable_hooks=True,
        constraints=dict(own_ip=application_host_ip),
        container=Mesos(image=DockerImage(
            name=docker_registry + '/serenity/tensorflow-train', tag=tensorflow_train_image_tag,
        )),
        task=SequentialTask(
            name='tensorflow_train--%s' % workload_uniq_id,
            resources=Resources(cpu=cpu, ram=ram, disk=disk),
            processes=[
                Process(
                    name='tensorflow_train_run',
                    cmdline="/wrapper.pex --command 'training --dataset_path '/' --batch_size {batch_size} "
                            "--epochs {epochs}' "
                            "--prometheus_port {prometheus_port} "
                            "--prometheus_ip '{prometheus_ip}' "
                            "--stderr 0 --kafka_brokers '{kafka_brokers}' --kafka_topic {kafka_topic} "
                            "--log_level {log_level} "
                            "--metric_name_prefix 'tensorflow_train_' "
                            "--slo {slo} --sli_metric_name tensorflow_train_images_processed --inverse_sli_metric_value "
                            "--peak_load 1 --load_metric_name const "
                            "--labels \"{labels}\"".format(batch_size=tensorflow_train_batch_size,
                                                           epochs=tensorflow_train_epochs,
                                                           prometheus_port=wrapper_prometheus_port,
                                                           prometheus_ip=application_host_ip,
                                                           kafka_brokers=wrapper_kafka_brokers,
                                                           log_level=wrapper_log_level,
                                                           kafka_topic='owca_apms_tensorflow_train',
                                                           labels=str(wrapper_labels), slo=slo
                                                           )
                )
            ],
        )
    )
]

hooks = [AddMetadata(wrapper_labels)]
